{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training Neural Networks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8_UwY7rGEjd"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def test_network(net, trainloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # Create Variables for the inputs and targets\n",
        "    inputs = Variable(images)\n",
        "    targets = Variable(images)\n",
        "\n",
        "    # Clear the gradients from all Variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass, then backward pass, then update weights\n",
        "    output = net.forward(inputs)\n",
        "    loss = criterion(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def view_recon(img, recon):\n",
        "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
        "        reconstruction also a PyTorch Tensor\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "    axes[0].imshow(img.numpy().squeeze())\n",
        "    axes[1].imshow(recon.data.numpy().squeeze())\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')\n",
        "\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1KDgyl5GWsu",
        "outputId": "c7fba82d-e1e0-4ba9-c381-8d795c12d3c9"
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get our data\n",
        "dataiter = iter(trainloader)\n",
        "\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3108, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoyMkdQeGr7x",
        "outputId": "396fd4d0-632f-4af8-c364-5dd66eddfd2f"
      },
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-1.0634e-04, -1.0634e-04, -1.0634e-04,  ..., -1.0634e-04,\n",
            "         -1.0634e-04, -1.0634e-04],\n",
            "        [ 7.6268e-05,  7.6268e-05,  7.6268e-05,  ...,  7.6268e-05,\n",
            "          7.6268e-05,  7.6268e-05],\n",
            "        ...,\n",
            "        [ 2.3326e-03,  2.3326e-03,  2.3326e-03,  ...,  2.3326e-03,\n",
            "          2.3326e-03,  2.3326e-03],\n",
            "        [-2.1100e-03, -2.1100e-03, -2.1100e-03,  ..., -2.1100e-03,\n",
            "         -2.1100e-03, -2.1100e-03],\n",
            "        [ 1.9809e-04,  1.9809e-04,  1.9809e-04,  ...,  1.9809e-04,\n",
            "          1.9809e-04,  1.9809e-04]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srASFi9qHbIl"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtdT0ooRHfI7",
        "outputId": "1f4aa3d8-e574-4e3e-b8b3-1d2cd370247f"
      },
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[-0.0285,  0.0082, -0.0197,  ..., -0.0111, -0.0261, -0.0294],\n",
            "        [-0.0098,  0.0179, -0.0099,  ..., -0.0009, -0.0255, -0.0127],\n",
            "        [-0.0281,  0.0281,  0.0347,  ...,  0.0016, -0.0087,  0.0153],\n",
            "        ...,\n",
            "        [-0.0341, -0.0079,  0.0019,  ...,  0.0144,  0.0069, -0.0027],\n",
            "        [ 0.0279, -0.0039,  0.0056,  ...,  0.0057,  0.0176,  0.0306],\n",
            "        [ 0.0029,  0.0125,  0.0209,  ...,  0.0237, -0.0024,  0.0091]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
            "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
            "        ...,\n",
            "        [-0.0015, -0.0015, -0.0015,  ..., -0.0015, -0.0015, -0.0015],\n",
            "        [-0.0006, -0.0006, -0.0006,  ..., -0.0006, -0.0006, -0.0006],\n",
            "        [ 0.0013,  0.0013,  0.0013,  ...,  0.0013,  0.0013,  0.0013]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx3coq_9Hjv8",
        "outputId": "ff3cf700-9f8b-47e4-e497-871aa38d8713"
      },
      "source": [
        "# Take an update step and view the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[-0.0285,  0.0082, -0.0197,  ..., -0.0111, -0.0261, -0.0294],\n",
            "        [-0.0098,  0.0179, -0.0099,  ..., -0.0009, -0.0254, -0.0127],\n",
            "        [-0.0281,  0.0281,  0.0347,  ...,  0.0016, -0.0087,  0.0153],\n",
            "        ...,\n",
            "        [-0.0340, -0.0079,  0.0019,  ...,  0.0144,  0.0070, -0.0027],\n",
            "        [ 0.0279, -0.0038,  0.0057,  ...,  0.0057,  0.0176,  0.0306],\n",
            "        [ 0.0029,  0.0125,  0.0208,  ...,  0.0237, -0.0025,  0.0091]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwTTsFKfHnV0",
        "outputId": "608611dd-2b16-4974-eff4-0f280c7c5b5e"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # TODO: Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "       \n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.9423272702485515\n",
            "Training loss: 0.8762724942235804\n",
            "Training loss: 0.5359862702551172\n",
            "Training loss: 0.43534895728455425\n",
            "Training loss: 0.38828924330058634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q80SWMUHxrM"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "CI5TlX3TIM5a",
        "outputId": "93006053-5274-423b-cacc-0e91584b807c"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XODihRBaJpWK"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    }
  ]
}